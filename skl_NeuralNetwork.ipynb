{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "hollywood-hampshire",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bb19016449fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataLoad import PulsarData\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-algeria",
   "metadata": {},
   "source": [
    "## Classification of pulsar data using the sklearn neural network method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = PulsarData('HTRU_2').features\n",
    "targets_data = PulsarData('HTRU_2').targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-answer",
   "metadata": {},
   "source": [
    "Shuffle and split the data into training and test groups with 3:1 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hundred-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_data, test_features_data, train_targets_data, test_targets_data  =  train_test_split( features_data, \n",
    "                                                        targets_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-lending",
   "metadata": {},
   "source": [
    "Bayesian optimisation and cross validation of hyperparameters using Simone's Troels example code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "outdoor-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklNN_CrossValidation(hidden_layer_sizes, learning_rate_init, data, targets):\n",
    "    \"\"\"Cross validation.\n",
    "       Fits a NN with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations\n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, learning_rate_init=learning_rate_init, random_state=0)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thermal-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_sklNN(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to NN parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(hidden_layer_sizes, learning_rate_init):\n",
    "        \"\"\"Wrapper of NNe cross validation. \n",
    "           hidden_layer_sizes\n",
    "           is cast to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return sklNN_CrossValidation(hidden_layer_sizes=int(hidden_layer_sizes), \n",
    "                                            learning_rate_init=learning_rate_init, \n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "established-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | hidden... | learni... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 187.9   \u001b[0m | \u001b[0m 0.9507  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9569  \u001b[0m | \u001b[95m 366.3   \u001b[0m | \u001b[95m 0.5987  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9727  \u001b[0m | \u001b[95m 78.85   \u001b[0m | \u001b[95m 0.1561  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 29.98   \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.9761  \u001b[0m | \u001b[95m 500.0   \u001b[0m | \u001b[95m 0.0001  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9755  \u001b[0m | \u001b[0m 496.5   \u001b[0m | \u001b[0m 0.1832  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9755  \u001b[0m | \u001b[0m 428.1   \u001b[0m | \u001b[0m 0.01407 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 114.0   \u001b[0m | \u001b[0m 0.9893  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.9765  \u001b[0m | \u001b[95m 274.3   \u001b[0m | \u001b[95m 0.008437\u001b[0m |\n",
      "=================================================\n",
      "{'target': 0.9765330380459971, 'params': {'hidden_layer_sizes': 274.3146737438626, 'learning_rate_init': 0.00843679678392597}}\n"
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"hidden_layer_sizes\": (1, 500), \n",
    "                                   \"learning_rate_init\": (0.0001, 1)\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_sklNN(train_features_data, \n",
    "                                             train_targets_data, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-wedding",
   "metadata": {},
   "source": [
    "Cross-validation on result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "internal-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766 accuracy with a standard deviation of 0.0023\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=int(BayesianOptimization.max['params']['hidden_layer_sizes']), \n",
    "                                 learning_rate_init=BayesianOptimization.max['params']['learning_rate_init'],\n",
    "                                 random_state=0)\n",
    "scores = cross_val_score(clf, features_data, targets_data, cv=5) \n",
    "print(f\"{scores.mean():.4f} accuracy with a standard deviation of {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-richardson",
   "metadata": {},
   "source": [
    "Comparing with baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convenient-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0682 improvement with a standard deviation of 0.0023\n"
     ]
    }
   ],
   "source": [
    "print(f\"{scores.mean()-PulsarData('HTRU_2').baseline:.4f} improvement with a standard deviation of {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-lindsay",
   "metadata": {},
   "source": [
    "Fit a gradient boosting classifier with hyperparameters optimised by Gaussian Process Optimisation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "derived-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fit = clf.fit(train_features_data, train_targets_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-franklin",
   "metadata": {},
   "source": [
    "Compare the classified data to the test set - returns percentage match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "monthly-arrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776536312849162"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_fit.score(test_features_data, test_targets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "central-support",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f513b317b4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/amas/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/amas/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_execute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_gradients_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m \u001b[0;31m# pylint: disable=E0611\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradients_impl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_gradients_impl\u001b[0m \u001b[0;31m# pylint: disable=E0611\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "shap_values = shap.DeepExplainer(clf_fit, train_features_data).shap_values(train_features_data)\n",
    "shap.summary_plot(shap_values, train_features_data, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-tongue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amas",
   "language": "python",
   "name": "amas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
