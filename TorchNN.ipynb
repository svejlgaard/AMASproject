{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataLoad import PulsarData\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pretty plotting\n",
    "plt.style.use('seaborn-paper')\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "source": [
    "Creating the neural network:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralN(nn.Module):\n",
    "    def __init__(self,inputsize,hiddensize):\n",
    "        super(NeuralN, self).__init__()\n",
    "        self.inputsize=inputsize\n",
    "        self.hiddensize=hiddensize\n",
    "        # an affine operation: y = Wx + b, this is basically a weight tensor!\n",
    "        self.fcinput = nn.Linear(in_features=self.inputsize, out_features=self.hiddensize)\n",
    "        self.fcoutput = nn.Linear(in_features=self.hiddensize, out_features=2)\n",
    "    \n",
    "    def forward(self,x: torch.Tensor):\n",
    "        x = x.to(dtype=torch.float)\n",
    "        x = self.fcinput(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fcoutput(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "Loading the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = PulsarData('HTRU_2').features\n",
    "raw_targets = PulsarData('HTRU_2').targets"
   ]
  },
  {
   "source": [
    "Defining the epochs for the neural network to train:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "source": [
    "Splitting data into test and train data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_data, test_features_data, train_targets_data, test_targets_data  =  train_test_split( raw_features, \n",
    "                                                        raw_targets, test_size=0.25, random_state=42)"
   ]
  },
  {
   "source": [
    "Writing a cross validation function that is compatible with torch: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_CrossValidation(hiddensize, learning_rate, data, targets):\n",
    "   cv = 3\n",
    "   net = NeuralN(data.shape[1], hiddensize)\n",
    "   dlist = np.array_split(data.to_numpy(), cv)\n",
    "   tlist = np.array_split(targets.to_numpy(), cv)\n",
    "   cval = list()\n",
    "   for d, dat in tqdm(enumerate(dlist)):\n",
    "      cross_dlist =  dlist[:d] + dlist[d+1 :]\n",
    "      cross_tlist =  tlist[:d] + tlist[d+1 :]\n",
    "      cross_dat = torch.from_numpy(np.concatenate(cross_dlist)).float()\n",
    "      cross_tar = torch.from_numpy(np.concatenate(cross_tlist)).long()\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "      optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "      net.train()\n",
    "      for e in range(epochs):\n",
    "         epoch_losses = list()\n",
    "         for n in range(cross_dat.shape[0]):\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad() \n",
    "            prediction = net(cross_dat[n]).unsqueeze(0)\n",
    "            target = cross_tar[n].unsqueeze(0)\n",
    "            # Calculating the loss function\n",
    "            loss = criterion(prediction,target)\n",
    "            epoch_losses.append(float(loss))\n",
    "            # Calculating the gradient\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      net.eval()\n",
    "      cross_pred = torch.argmax(net(torch.from_numpy(dat).float()),dim=1)\n",
    "      acc_cross = torch.mean((cross_pred == torch.from_numpy(tlist[d]).long()).float())\n",
    "      cval.append(acc_cross)\n",
    "\n",
    "   return np.mean(np.array(cval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_NN(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Neural Network parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(hiddensize, learning_rate):\n",
    "        \"\"\"Wrapper of Neural Network cross validation. \n",
    "           Notice how we ensure params are casted to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return NN_CrossValidation(hiddensize=int(hiddensize), \n",
    "                                            learning_rate=learning_rate, \n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    boptimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    boptimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return boptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]|   iter    |  target   | hidden... | learni... |\n",
      "-------------------------------------------------\n",
      "3it [07:21, 147.14s/it]\n",
      "0it [00:00, ?it/s]| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 193.5   \u001b[0m | \u001b[0m 0.4754  \u001b[0m |\n",
      "3it [07:19, 146.40s/it]\n",
      "0it [00:00, ?it/s]| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 368.7   \u001b[0m | \u001b[0m 0.2993  \u001b[0m |\n",
      "3it [04:39, 93.27s/it]\n",
      "0it [00:00, ?it/s]| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9306  \u001b[0m | \u001b[95m 86.45   \u001b[0m | \u001b[95m 0.07801 \u001b[0m |\n",
      "3it [04:39, 93.15s/it]\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 38.46   \u001b[0m | \u001b[0m 0.4331  \u001b[0m |\n",
      "3it [06:06, 122.28s/it]\n",
      "0it [00:00, ?it/s]| \u001b[95m 5       \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 500.0   \u001b[0m | \u001b[95m 1e-05   \u001b[0m |\n",
      "3it [06:54, 138.22s/it]\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 496.7   \u001b[0m | \u001b[0m 0.1936  \u001b[0m |\n",
      "3it [06:14, 124.69s/it]\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.965   \u001b[0m | \u001b[0m 284.5   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "3it [06:21, 127.14s/it]\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 141.3   \u001b[0m | \u001b[0m 0.4997  \u001b[0m |\n",
      "3it [06:45, 135.29s/it]| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 327.5   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=================================================\n",
      "{'target': 0.9664767384529114, 'params': {'hiddensize': 500.0, 'learning_rate': 1e-05}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"hiddensize\": (10, 500), \n",
    "                                   \"learning_rate\": (0.00001, 0.5),\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_NN(raw_features, \n",
    "                                             raw_targets, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "source": [
    "Creating a neural network with the optimal hiddensize:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(BayesianOptimization.max['params']['learning_rate'])\n",
    "net = NeuralNetClassifier(NeuralN(inputsize=raw_features.shape[1], hiddensize=int(BayesianOptimization.max['params']['hiddensize'])), max_epochs=epochs, lr=BayesianOptimization.max['params']['learning_rate'],iterator_train__shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0917\u001b[0m           nan  0.4672\n",
      "      2           nan       0.0917           nan  0.3189\n",
      "      3           nan       0.0917           nan  0.3929\n",
      "      4           nan       0.0917           nan  0.3266\n",
      "      5           nan       0.0917           nan  0.3534\n",
      "      6           nan       0.0917           nan  0.3414\n",
      "      7           nan       0.0917           nan  0.3289\n",
      "      8           nan       0.0917           nan  0.3110\n",
      "      9           nan       0.0917           nan  0.4295\n",
      "     10           nan       0.0917           nan  0.4318\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0917\u001b[0m           nan  0.4354\n",
      "      2           nan       0.0917           nan  0.3482\n",
      "      3           nan       0.0917           nan  0.3083\n",
      "      4           nan       0.0917           nan  0.3520\n",
      "      5           nan       0.0917           nan  0.3620\n",
      "      6           nan       0.0917           nan  0.3731\n",
      "      7           nan       0.0917           nan  0.2923\n",
      "      8           nan       0.0917           nan  0.4047\n",
      "      9           nan       0.0917           nan  0.3530\n",
      "     10           nan       0.0917           nan  0.3163\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1           nan       \u001b[32m0.0917\u001b[0m           nan  0.2909\n",
      "      2           nan       0.0917           nan  0.3681\n",
      "      3           nan       0.0917           nan  0.2970\n",
      "      4           nan       0.0917           nan  0.2899\n",
      "      5           nan       0.0917           nan  0.2926\n",
      "      6           nan       0.0917           nan  0.3195\n",
      "      7           nan       0.0917           nan  0.3088\n",
      "      8           nan       0.0917           nan  0.2691\n",
      "      9           nan       0.0917           nan  0.3035\n",
      "     10           nan       0.0917           nan  0.3686\n",
      "0.1678 accuracy with a standard deviation of 0.0001\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'abe' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1817d0f47783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{scores.mean():.4f} accuracy with a standard deviation of {scores.std():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'abe' is not defined"
     ]
    }
   ],
   "source": [
    "#features_data = PulsarData('HTRU_2').features\n",
    "#targets_data = PulsarData('HTRU_2').targets\n",
    "scores = cross_val_score(net, raw_features.to_numpy(), raw_targets.to_numpy(), cv=3, scoring='f1') \n",
    "print(f\"{scores.mean():.4f} accuracy with a standard deviation of {scores.std():.4f}\")\n",
    "print(abe)"
   ]
  },
  {
   "source": [
    "Converting data into torch tensors:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'to_numpy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3ce4e1675de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_targets_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_targets_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_targets_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "train_features_data, test_features_data = torch.from_numpy(train_features_data.to_numpy()).float(), torch.from_numpy(test_features_data.to_numpy()).float()\n",
    "train_targets_data, test_targets_data = torch.from_numpy(train_targets_data.to_numpy()).long(), torch.from_numpy(test_targets_data.to_numpy()).long()"
   ]
  },
  {
   "source": [
    "Setting the optimal learning rate and training the network:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NeuralN(\n",
       "  (fcinput): Linear(in_features=8, out_features=49, bias=True)\n",
       "  (fcoutput): Linear(in_features=49, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=BayesianOptimization.max['params']['learning_rate'])\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.11904058890842346\n",
      "1 0.1070697266854844\n",
      "2 0.10629891285761564\n",
      "3 0.10584857639593982\n",
      "4 0.1047456630957333\n",
      "5 0.10412013706289666\n",
      "6 0.10293075028365872\n",
      "7 0.10230069415726191\n",
      "8 0.10131413117006917\n",
      "9 0.10080707330719037\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NeuralN(\n",
       "  (fcinput): Linear(in_features=8, out_features=49, bias=True)\n",
       "  (fcoutput): Linear(in_features=49, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    epoch_losses = list()\n",
    "    for n in range(train_features_data.shape[0]):\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad() \n",
    "        prediction = net(train_features_data[n]).unsqueeze(0)\n",
    "        target = train_targets_data[n].unsqueeze(0)\n",
    "        # Calculating the loss function\n",
    "        loss = criterion(prediction,target)\n",
    "        epoch_losses.append(float(loss))\n",
    "        # Calculating the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(e, np.mean(epoch_losses))\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "source": [
    "Final result for train data and test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.9770) tensor(0.9774)\n"
     ]
    }
   ],
   "source": [
    "train_prediction = torch.argmax(net(train_features_data),dim=1)\n",
    "acc_train = torch.mean((train_prediction == train_targets_data).float())\n",
    "test_prediction = torch.argmax(net(test_features_data),dim=1)\n",
    "acc_test = torch.mean((test_prediction == test_targets_data).float())\n",
    "\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4af73984da9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_data\u001b[0m   \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shap/explainers/deep/deep_pytorch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    466\u001b[0m                           \u001b[0;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                           'incorrect results).', category=RuntimeWarning)\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shap_values = shap.DeepExplainer(net, train_features_data   ).shap_values(train_features_data)\n",
    "shap.summary_plot(shap_values, train_features_data, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}